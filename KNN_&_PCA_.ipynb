{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4VRYuTdvaBS",
        "outputId": "3096306b-732f-4ff0-82e0-42ab36cd0ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy with PCA: 0.944\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create pipeline with PCA and KNN\n",
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),      # Step 1: Standardize features\n",
        "    ('pca', PCA(n_components=5)),      # Step 2: Reduce dimensions to 5 components\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=3))  # Step 3: Apply KNN\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"KNN Accuracy with PCA:\", round(accuracy, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------------------------\n",
        "# 1. KNN WITHOUT SCALING\n",
        "# -------------------------\n",
        "knn_unscaled = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = knn_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "# -------------------------\n",
        "# 2. KNN WITH SCALING\n",
        "# -------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_scaled = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# -------------------------\n",
        "# Print Results\n",
        "# -------------------------\n",
        "print(\"KNN Accuracy without Scaling:\", round(accuracy_unscaled, 3))\n",
        "print(\"KNN Accuracy with Scaling:   \", round(accuracy_scaled, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuMV9r9Jvi5F",
        "outputId": "5567ae1c-f432-4197-a770-9ec183a3a5a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy without Scaling: 0.722\n",
            "KNN Accuracy with Scaling:    0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "\n",
        "# Step 1: Standardize the data (important before PCA)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 2: Apply PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Step 3: Print explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Display results in a table format\n",
        "pca_results = pd.DataFrame({\n",
        "    'Principal Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
        "    'Explained Variance Ratio': explained_variance\n",
        "})\n",
        "\n",
        "print(pca_results)\n",
        "print(\"\\nTotal Variance Explained:\", round(sum(explained_variance), 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2ghLIeWvxgv",
        "outputId": "473e1616-000f-42ba-b34d-09b7df5d6349"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Principal Component  Explained Variance Ratio\n",
            "0                  PC1                  0.361988\n",
            "1                  PC2                  0.192075\n",
            "2                  PC3                  0.111236\n",
            "3                  PC4                  0.070690\n",
            "4                  PC5                  0.065633\n",
            "5                  PC6                  0.049358\n",
            "6                  PC7                  0.042387\n",
            "7                  PC8                  0.026807\n",
            "8                  PC9                  0.022222\n",
            "9                 PC10                  0.019300\n",
            "10                PC11                  0.017368\n",
            "11                PC12                  0.012982\n",
            "12                PC13                  0.007952\n",
            "\n",
            "Total Variance Explained: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the original dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# -------------------------\n",
        "# 1. KNN on ORIGINAL dataset\n",
        "# -------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_original = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_original.fit(X_train_scaled, y_train)\n",
        "y_pred_original = knn_original.predict(X_test_scaled)\n",
        "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
        "\n",
        "# -------------------------\n",
        "# 2. KNN on PCA-transformed dataset (Top 2 components)\n",
        "# -------------------------\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = knn_pca.predict(X_test_pca)\n",
        "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
        "\n",
        "# -------------------------\n",
        "# Print Results\n",
        "# -------------------------\n",
        "print(\"KNN Accuracy on ORIGINAL dataset:\", round(accuracy_original, 3))\n",
        "print(\"KNN Accuracy on PCA-transformed dataset (2 components):\", round(accuracy_pca, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIPnTPjzv-hd",
        "outputId": "e495a177-2792-420c-8006-0b8737fae4ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy on ORIGINAL dataset: 0.944\n",
            "KNN Accuracy on PCA-transformed dataset (2 components): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# -------------------------\n",
        "# 1. KNN with Euclidean distance (default)\n",
        "# -------------------------\n",
        "knn_euclidean = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
        "knn_euclidean.fit(X_train_scaled, y_train)\n",
        "y_pred_euclidean = knn_euclidean.predict(X_test_scaled)\n",
        "accuracy_euclidean = accuracy_score(y_test, y_pred_euclidean)\n",
        "\n",
        "# -------------------------\n",
        "# 2. KNN with Manhattan distance\n",
        "# -------------------------\n",
        "knn_manhattan = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
        "knn_manhattan.fit(X_train_scaled, y_train)\n",
        "y_pred_manhattan = knn_manhattan.predict(X_test_scaled)\n",
        "accuracy_manhattan = accuracy_score(y_test, y_pred_manhattan)\n",
        "\n",
        "# -------------------------\n",
        "# Print Results\n",
        "# -------------------------\n",
        "print(\"KNN Accuracy with Euclidean distance:\", round(accuracy_euclidean, 3))\n",
        "print(\"KNN Accuracy with Manhattan distance:\", round(accuracy_manhattan, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCBQ1MqNwT--",
        "outputId": "4e120341-e447-40fa-c258-3426aa79ead6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy with Euclidean distance: 0.944\n",
            "KNN Accuracy with Manhattan distance: 0.944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Simulate high-dimensional gene expression dataset\n",
        "X, y = make_classification(n_samples=100, n_features=500, n_informative=50,\n",
        "                           n_redundant=450, n_classes=3, random_state=42)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 1: Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Step 2: Apply PCA (retain 95% variance)\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(\"Original number of features:\", X.shape[1])\n",
        "print(\"Reduced number of features:\", X_train_pca.shape[1])\n",
        "\n",
        "# Step 3: Train KNN classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_pca, y_train)\n",
        "\n",
        "# Step 4: Predictions\n",
        "y_pred = knn.predict(X_test_pca)\n",
        "\n",
        "# Step 5: Evaluate the model\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Step 6: Cross-validation for robustness\n",
        "cv_scores = cross_val_score(knn, X_train_pca, y_train, cv=5)\n",
        "print(\"\\nCross-validation Accuracy:\", round(cv_scores.mean(), 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSOxuElHwjFU",
        "outputId": "f55218ed-30ba-49c9-a7ad-44085dc3107e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: 500\n",
            "Reduced number of features: 35\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         6\n",
            "           1       0.73      1.00      0.84         8\n",
            "           2       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           0.85        20\n",
            "   macro avg       0.91      0.83      0.84        20\n",
            "weighted avg       0.89      0.85      0.84        20\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[3 3 0]\n",
            " [0 8 0]\n",
            " [0 0 6]]\n",
            "\n",
            "Cross-validation Accuracy: 0.575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nXVz1WxwyQu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}